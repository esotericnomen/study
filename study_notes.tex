\title{\~Study Notes}
\date{Last updated on : \today}

\documentclass[12pt]{article}
%\usepackage{hyperref}% http://ctan.org/pkg/hyperref
%\usepackage{bookmark}% http://ctan.org/pkg/bookmark
\usepackage[bookmarks,bookmarksopen,bookmarksdepth=9]{hyperref}
\usepackage{scrextend}	% For margin
\usepackage{xcolor}	% For colors
\usepackage{tikz} % For tree
\usepackage{tikz-qtree}

\begin{document}
\maketitle
\pagebreak
%\begin{abstract}
%This is the paper's abstract \ldots
%\end{abstract}

\pagebreak
\vspace*{\fill}
\begin{center}
\section{English Vocabulary}
\end{center}
\vspace*{\fill}
\pagebreak

This is study notes on The Structure of English Words (LING150) course from http://darkwing.uoregon.edu/~l150web/index.html
\subsection{Course Organization}
\begin{itemize}
\item \textbf{Unit 1:} Basic Word Analysis
\begin{itemize}
\item Historical sources of English words
\item Basic principles of word analysis (morphology)
\end{itemize}
\item \textbf{Unit 2:} Intermediate Word Analysis and Basic Phonetics
\begin{itemize}
\item Alternations in morpheme forms (allomorphy)
\item Basic principles of English sounds (phonetics)
\end{itemize}
\item \textbf{Unit 3:} Advanced Word Analysis and Semantic Change
\begin{itemize}
\item More alternations in morpheme forms (allomorphy rules)
\item Historical changes of meanings (semantic change)
\end{itemize}
\item \textbf{Unit 4:} - The Origins and History of English
\begin{itemize}
\item Pre-history of English and Indo-European languages
\item English history
\end{itemize}
\end{itemize}

\subsection{Introduction to English vocabulary}
\subsubsection{Sources of English words}
\begin{itemize}
\item Native words
\item Borrowed Words
\begin{itemize}
\item Exotic Languages
\item Classic Languages
\begin{itemize}
\item Greek
\item Latin
\end{itemize}
\end{itemize}
\end{itemize}

The native words are words which are used in evryday conversations. The native words falls into follwoing categories. \\
\\
\begin{tabular}{| l | c | }
	\hline	
		\textbf{Type} & \textbf{Example} \\
		\hline 		\hline
		Body Parts & Foot, mouth, hand, leg \\ \hline
		Family Relationships / Kinship terms & Father, mother, brother, sister \\ \hline
		Everyday, Natural objects &  rock, house, hill \\ \hline
		Physical Acts &  think, drive, ride \\ \hline
		Physical charactrestics  & red, cold, young \\ \hline 
\end{tabular}
\subsubsection{Learning Model}
Learning new words and improving new vocabulary can be carried out by the following ways.
\begin{itemize}
\item Absorption
\item Memorization
\item Analysis
\end{itemize}

\subsection{Analyzing words}
\subsubsection{Morphemes}
Word analysis involves breaking a word into its morphemes. Literally morphemes means \textbf{\textit{an element in a system of forms.}}\\
In linugustics, it is defined as 
\begin{addmargin}[3em]{2em}% 1em left, 2em right
"The smallest \textbf{\textit{form}} which is paired with a particular \textbf{\textit{meaning}}"
\end{addmargin} 
From Dictionary: \textbf{\textit{morpheme}}, noun, very rare\\
\begin{addmargin}[3em]{2em}% 1em left, 2em right
	Minimal meaningful language unit;\\ 
	It cannot be divided into smaller meaningful units;
\end{addmargin}

\subsubsection{Characteristics of morphemes}
Morphemes have four defining characteristics:
\begin{itemize}
\item \color{blue} They cannot be subdivided.
\color{black} \item \color{blue} They add meaning to a word.
\color{black} \item \color{blue} They can appear in many different words.
\color{black} \item \color{blue} They can have any number of syllables.
\end{itemize}
\color{black}

\subsubsection{Problems with morphemes}
There is no one-to-one mapping between \textit{FORM} $\leftrightarrow$ \textit{MEANING}
\begin{itemize}
\item One form, two (or more) meanings.
	\begin{addmargin}[3em]{2em}% 1em left, 2em right
	\color{red}\textbf{in}- \color{blue}'\textit{not}' \color{black}in words like \color{red}\textbf{in}\color{black}capable and \color{red}\textbf{in}\color{black}sufficient, \& \\
	\color{red}\textbf{in}- \color{blue}'\textit{into, within}', \color{black}as in \color{red}\textbf{in}\color{black}vade and \color{red}\textbf{in}\color{black}clude.
	\end{addmargin}

\item Two (or more) forms, one meaning.
\begin{itemize}
\item Two (or more) forms, one meaning = two morphemes
	\begin{addmargin}[3em]{2em}% 1em left, 2em right
	\color{red}\textbf{andr}- \color{blue}'\textit{man,male}' \color{black}in words like \color{red}\textbf{and}\color{black}roid \& \\
	\color{red}\textbf{vir}- \color{blue}'\textit{man,male}', \color{black}as in \color{red}\textbf{vir}\color{black}ile
	\end{addmargin}

\item Two (or more) forms, one meaning = one morpheme
	\begin{addmargin}[3em]{2em}% 1em left, 2em right
		\color{red} \textbf{pan-} \color{black} and \color{red} \textbf{pant-} \color{black}, which are different forms of a Greek morpheme meaning \color{blue}'all,overall'. 
	\end{addmargin}

\end{itemize}
\end{itemize}
The alternate forms of a single morpheme are called \color{blue}\textbf{allomorphs},\color{black} literally 'other forms.' 

\subsubsection{How to analyze words}
\begin{itemize}
\item Only Words borrowed from Classic languages like Greek and Latin can be analyzed
\item Native words or words borrowed from exotice languages can not be analyzed
\end{itemize}
There are four steps as following in analyzing a word
\begin{itemize}
\item Parse : Divide it into its morpheme
\item Gloss : Give the meaning for a morpheme
\item Give a literal meaning :  Use the meanings from the glosses to construct a literal meaning
\item Give a dictionary definition : Extended literal meaning metaphorically to arrive at the actual meaning.
\end{itemize}

Example :
	\begin{addmargin}[3em]{2em}% 1em left, 2em right
	\begin{itemize}
	\item \color{red} \textbf{repellent} \color{black} 
	\item re-  /  pel  /  (l)  /  -ent
	\item 'again, back' / 'push' / (l) / A, N
	\item 'something which pushes back' / (l) /A,N
	\end{itemize}
	\end{addmargin}
	
'A, N.' : The letters stand for 'ADJECTIVE, NOUN'

\subsection{Words - their construction and use}
\begin{enumerate}
\item How words are constructed
\begin{enumerate}
\item Types of Roots
\item Types of Affixes
\end{enumerate}
\item How words are used - NOUNS, VERBS and ADJECTIVES
\end{enumerate}

\subsubsection{How words are constructed}
\begin{center}
\Tree [.Morphemes [.ROOTS [.Free\ Root ] [.Bounded\ Root ]] [.AFFIXES [.Prefixes ] [.Suffixes ] ]]
\end{center}
\paragraph{Roots}
\begin{itemize}
\item Roots usually have a rather specific meaning
\item This meaning tends to be relatively constant across all the words that use the root. 
\item Roots also contribute the greatest conceptual content to the overall meaning of the word.
\item Every word has at the least one root. 
\item Roots have freer distribution; that is, they can occur almost anywhere in a word
\item Two ore more roots combine to form Compound words.
\item Compound words may or may not have affixes.
\end{itemize}

\subparagraph{Free Roots}
\begin{itemize}
\item Free Roots are roots that can occur alone as whole words
\item They can stand alone as single words.
\item Free roots can also be combined with other roots or affixes to form more complex words
\end{itemize}

\subparagraph{Bounded Roots}
\begin{itemize}
\item Bound Roots can never occur alone as whole words.
\item They cannot stand alone; 
\item They must occur in combination with other morphemes
\item Almost all the Latin and Greek roots we are studying are bound roots
\end{itemize}

\paragraph{Affixes}
\begin{itemize}
\item Affixes are morphemes which attach to roots or a combination of roots and other affixes. 
\item Their main use is to modify the meaning conveyed by the root or roots.
\item Affixes by definition are always bound or affixed to a root. 
\item They are divided into two different types depending on where they attach to the root.
\item \color{blue}Prefixes \color{black}occur before a root (although several prefixes can be strung together before a single root).
\item \color{blue}Suffixes \color{black}occur after a root (although multiple suffixes can occur at the ends of words).
\end{itemize}

\subsection{Suffixes and Prefixes}
\begin{enumerate}
\item Suffixes 
\begin{enumerate}
\item Inflectional suffixes
\begin{itemize}
\item Add only grammatical information
\item Never change the part of speech
\end{itemize}
\item Derivational suffixes
\begin{itemize}
\item Make a new word with a new meaning
\item Usually change the part of speech
\end{itemize}
\item Meanings of Derivational Suffixes
\end{enumerate}

\item Prefixes
\begin{enumerate} 
\item Spatial Prefixes
\begin{itemize}
\item The largest group of prefixes denote relationships that occur in space.
\end{itemize}
\item Non-Spatial Prefixes
\begin{itemize}
\item Comparative relations
\item Quantity and Size
\item Negative Prefixes
\item Intensive prefixes
\end{itemize}
\end{enumerate}
\end{enumerate}



\pagebreak
\vspace*{\fill}
\begin{center}
\section{Number-Theoretic Reference Problems}
\end{center}
\vspace*{\fill}
\pagebreak
\subsection{Introduction}
\begin{itemize}
\item Security of many public-key cryptosystems dependent on intractability of the computational problems.
\item A problem is tractable if its possible to solve in polynomial time.
\item Problem \textit{A} can be said as reducable to Problem \textit{B}, if A can be solved by employing B and other finite operations $\xi.$
\item If A $\leq_{p}$ B, (i.e, A is reducable to B), then A is \textit{Computationaly Equivalent} to B, written as A $\equiv_{p}$ B
\item If  A $\equiv_{p}$ B, then both are tractabe or intractable.
\end{itemize} 

\subsection{Integer Factorization Problem}
\begin{itemize}
\item Given a positive integer $\textit{n}$, find its prime factors;
\item Write n $\mid$ $n = p_{1}^{e_{1}}p_{2}^{e_{2}}...p_{k}^{e_{k}}$, where $p_{i}$ are pairwise primes and $e_{i} \geq 1.$
\item  A set of integers is said to be pairwise coprime if a and b are coprime for every pair (a, b) of different integers in it.
\end{itemize}

\section{Cryptographic Primitives}
\subsection{Introduction}
\paragraph{A symmetric or private-key cipher} is one in which knowledge of the encryption key is explicitly or implicitly equivalent to knowing the decryption key.
\paragraph{An asymmetric or public-key cipher} is one in which the encryption key is effectively public knowledge, without giving any useful information about the decryption key.

\paragraph{trapdoor } is a computation which runs much more easily in one direction than back.

\paragraph{Example : }Multiplication of large integers is easy, while factoring of large integers is difficult.\\
Merely testing large numbers for primality is easy.

\subsection{RSA Cipher}
\begin{enumerate}
\item Generate two primes, p and q, such that, atleast $>2^{512}$ or preferably $>2^{1024}$
\item Compute \textbf{RSA Modulus, n =p.q}
\item Choose encryption exponent, \textbf{e} $> 2$, \textbf{randomly.} \\
Often, its \textbf{Fermats number} [A positive integer, of form, \textbf{$F_{n}=2^{2^{n}} + 1$} ]\\
\begin{center}
e = $2^{16} +1 = 65537$
\end{center}
\item Make \textbf{\textit{n}} and \textbf{\textit{e}} public
\item Compute decryption exponent, such that,\\
\begin{center}
$e.d = 1 \hspace{5pt} mod \hspace{5pt} (p-1)(q-1)$
\end{center}
\item Encryption : $E_{n,e}(x) = x ^{e} \hspace{5pt} \% \hspace{5pt}n \Rightarrow y $
\item Decryption : $D_{n,d}(y) = y ^{d} \hspace{5pt} \% \hspace{5pt}n \Rightarrow x $
\end{enumerate}

\pagebreak
\section{Logrithms}
\subsection{Logarithm definition}

If, a number \textit{b} is raised to a power \textit{x}, such that,\\
\begin{center}	$b^{x} = y$		\end{center}

Then the base b logarithm of x is equal to y:

\begin{center} 	log$_{b}(x) = y$	\end{center}

Then, we can conjure logrithms as the inverse of exponentiation, like
\begin{center}	$b^{y} = x $		\end{center}
\paragraph{Example :\\}
\begin{center}
log$_{2}(32) = 5$	$\Rightarrow 2^{5} = 32 $
\\log$_{2}(16) = 4$ $\Rightarrow 2^{4} = 16 $
\\log$_{2}(8) = 3$ $\Rightarrow 2^{3} = 8 $
\end{center}

\subsection{Logrithms Rules}
\begin{tabular}{| l | c | }
	\hline	
		\textbf{Rule} & \textbf{Explanation} \\
		\hline
		\hline
		Logarithm product rule 		& $log_{b}(x . y) = log_{b}(x) + log_{b}(y)$ \\ \hline
		Logarithm quotient rule 		& $log_{b}(x / y) = log_{b}(x) - log_{b}(y)$ \\ \hline
		Logarithm power rule			& $log_{b}(x ^{y}) = y . log_{b}(x)$  \\ \hline
		Logarithm base switch rule 	& $log_{b}(c) = 1 / log_{c}(b)$	\\ \hline
		Logarithm base change rule 	& $log_{b}(x) = log_{c}(x) / log_{c}(b)$	\\ \hline
		Derivative of logarithm		& $f(x) = log_{b}(x) \Rightarrow f^{'}(x) = 1 / ( x ln(b))$ \\ \hline
		Integral of logarithm		& $\int log_{b}(x) dx = x . ( log_{b}(x) - 1 / ln(b) ) + C$  \\ \hline
		Logarithm of negative number & $log_{b}(x)$ is undefined when $x \le 0$   \\ \hline
		Logarithm of 0				& $log_{b}(0)$ is undefined \\ & $\lim_{x\to 0^+}\textup{log}_b(x)=-\infty$   \\ \hline
		Logarithm of 1				& $log_{b}(1) = 0$  \\ \hline
		Logarithm of the base		& $log_{b}(b) = 1$  \\ \hline
\end{tabular}

\section{English Syllables}
\paragraph{Divide words based on the number of vowels: } The number of syllables in a word coincide with the number of vowel sounds you hear when speaking the word.  \\

Example : B\underline{a} $\mid n\underline{a} \mid$ n\underline{a}

\paragraph{Vovels:} 'a,' 'e,' 'i,' 'o,' 'u' and 'y' are considered as vovewls, when found in the middle or at the end of a word.

\subparagraph{Subtract 1 for each silent vowel in the word:} Example : 'came' and 'gone,' 'E' is the most common silent vowel.

\subparagraph{Consider words ending in 'le' as a vowel:} Divide the word before the consonant right before the 'le'. \\
Example : Little would be divided lit/tle; fumble as fum/ble; able as a/ble.

\subparagraph{Count diphthongs as 1 syllable instead of 2 : } diphthongs are two vowels, combinedly giving one syllabel. Example : Words like 'h\underline{au}l,' 'm\underline{oo}n,' and 'c\underline{oi}l' are diphthongs.

\subparagraph{Split words between consonants, surrounded by vowels.} Example :  hap/py, din/ner, bas/ket, un/der. 

\subparagraph{Find syllables by splitting a word before a single consonant. Examples are: au/tumn, o/pen, de/tail:}

\subparagraph{Mark prefixes and suffixes as syllabels: }

\pagebreak
\section{Group}

A group G is a finite or infinite set of elements together with a binary operation (called the group operation) that together satisfy the four fundamental properties of \#1 closure, \#2 associativity, \#3 the identity property, and \#4 the inverse property. 

\paragraph{1. Closure:} If A and B are two elements in G, then the product AB is also in G.

\paragraph{2. Associativity:} The defined multiplication is associative, i.e., for all A,B,C in G, (AB)C=A(BC).

\paragraph{3. Identity:} There is an identity element I (a.k.a. 1, E, or e) such that IA=AI=A for every element A in G.

\paragraph{4. Inverse:} There must be an inverse (a.k.a. reciprocal) of each element. Therefore, for each element A of G, the set contains an element B=A\^(-1) such that AA\^(-1)=A\^(-1)A=I.

\paragraph{Group Theory:} Study of groups.

\paragraph{Finite Group:} The group has a finite number of elements.

\paragraph{Subgroup:} A subset of group, which is \textit{closed} under \textit{group operation} is called as subgroup.

\paragraph{Cyclic Group:} Cyclic group is a group, that is generated by a single element. That is,
\begin{itemize}
\item It consists of a set of elemnets, with single invertible assosiative operation and
\item a element g, such that, every other element in the group can be obtained by applying the group operation or its inverse to g.
\end{itemize}

Cyclic group is closed under addition, associative and has unique inverse.

\paragraph{Homomorphism:} A map between two groups, which preserve identity and group operation is called Homomorphism.

\paragraph{Isomorphism:} If a homomorphism has an inverse which is also an homomorphism, this is called as \textit{isomorphism} and the two group is said to be isomorphic.
\pagebreak
\section{Android Services}
\label{Android Services}

We will see, 
\begin{enumerate}
\item What is a Service?
\item Service Lifecycle
\item Permissions
\item Process Lifecycle
\item Local Service Sample
\item Remote Messenger Service Sample
\end{enumerate}

\subsection{Introduction}
A Service is an application component, representing either 
\begin{itemize}
\item{an application's desire to perform a longer-running operation while not interacting with the user. \textit{This corresponds to calls to \textbf{Context.startService()}}}
\item{to supply functionality for other applications to use. \textit{This corresponds to calls to \textbf{Context.bindService()}}}
\end{itemize} 
Service is 
\begin{itemize}
\item Not a seperate process
\item Not a seperate thread
\end{itemize}
Each service class must have a corresponding $<$service$>$ declaration in its package's \textit{\textbf{AndroidManifest.xml.}} \\
Services can be started with \textbf{\textit{Context.startService()}} and \textbf{\textit{Context.bindService().}}\\


\subsection{Service Lifecycle}
 If someone calls \textit{Context.startService()} $\longrightarrow$ \textit{onCreate()} $\longrightarrow$ \\ \textit{onStartCommand(Intent, int, int) } $\longrightarrow$  run until \textit{Context.stopService()} or \textit{stopSelf()} is called

\textit{START\_STICKY} is used for services that are explicitly started and stopped as needed. \\
\textit{START\_NOT\_STICKY} or \textit{START\_REDELIVER\_INTENT} are used for services that should only remain running while processing any commands sent to them.\\
\textit{onDestroy()} method is called and the service is effectively terminated.

\subsection{Permissions}
Global access to a service can be enforced when it is declared in its manifest's $<$service$>$ tag. 
By doing so, other applications will need to declare a corresponding $<$uses-permission$>$ element in their own manifest to be able to start, stop, or bind to the service.\\
This can be bypassed by using \textit{Intent.FLAG\_GRANT\_READ\_URI\_PERMISSION} and/or \textit{Intent.FLAG\_GRANT\_WRITE\_URI\_PERMISSION }on the Intent, when using \textit{Context.startService(Intent)}.
\pagebreak
\section{Two step verification : }
\subsection{Factors of Authentication}
\begin{tabular}{| l | c | r | p{0.000002}}
	\hline	
		Factor & Explanation & Example\\
		\hline
		\hline
		Ownership factor & Something that user has & ID Card, A hardware, Token \\ \hline
		Knowledge factor & Something that user knows & Password, PIN \\	\hline
		Inherence factor & Something that is inhere to user & Biometrics like fingerprint, retina etc\\
	\hline
\end{tabular}
\subsection{Two step verification : }
For a secured and positive authentication, atleast there should be two or all three factors involve in authentication.
\paragraph{Single Sign On} A method to authenticate in a system which has multiple secured, independent systems. By this Single Sig On, a user logins in and autheticates one system and gains acess to all the systems.
\pagebreak
\section{Newline representation  : }

\paragraph{Carriage Return [CR] : } Reset typewriters horizontal position to the far left.
\paragraph{Line Feed [LF] : } Advance the paper by one line.
\\
\\
\textit{ASCII }Based systems 

A type writer typically needs both.
Windows uses CR+LF.
Linux uses only LF.
MAC OS, prior to OS-X used CR alone.
\\

IBM Pc's based on EBCDIC uses a special character called as \textit{Newline \textbf{[NL]}}
\pagebreak

\section{Turing Machine}

A Turing machine can be thought of as a primitive, abstract computer. Alan Turing, who was a British mathematician and cryptographer, invented the Turing machine as a tool for studying the computability of mathematical functions. Turing's hypothesis (also known has Church's thesis) is a widely held belief that a function is computable if and only if it can be computed by a Turing machine. This implies that Turing machines can solve any problem that a modern computer program can solve. There are problems that can not be solved by a Turing machine (e.g., the halting problem); thus, these problems can not be solved by a modern computer program.

\subsection{Components of a Turing Machine}
A Turing machine has
\begin{itemize}
\item an infinite tape that consists of adjacent cells (or squares). 
\item On each cell is written a symbol. The symbols that are allowed on the tape are finite in number and include the blank symbol. 
\item Each Turing machine has it's own alphabet (i.e., finite set of symbols), which determines the symbols that are allowed on the tape.
\item a tape head that is positioned over a cell on the tape. This tape head is able to read a symbol from a cell and write a new symbol onto a cell. 
\item The tape head can also move to an adjacent cell (either to the left or to the right).
\item A Turing machine has a finite number of states, and, at any point in time, a Turing machine is in one of these states. 
\item A Turing machine begins its operation in the start state. 
\item A Turing machine halts when it moves into one of the halt states.
\end{itemize} 
\pagebreak
\subsection{Opeartion of a Turing Machine}
\begin{enumerate}
\item The Turing machine reads the tape symbol that is under the Turing machine's tape head. This symbol is referred to as the current symbol.
\item The Turing machine uses its transition function to map the following: 
\begin{center}
\{the current state and current symbol\} =  \{the next state, the next symbol and the movement for the tape head.\}
\end{center}
\item The Turing machine changes its state to the next state, which was returned by the transition function.
\item The Turing machine overwrites the current symbol on the tape with the next symbol, which was returned by the transition function.
\item The Turing machine moves its tape head one symbol to the left or to the right, or does not move the tape head, depending on the value of the 'movement' that is returned by the transition function.
\item If the Turing machine's state is a halt state, then the Turing machine halts. Otherwise, repeat sub-step \#1.
\end{enumerate}

\section{NP Complete}
Decision problem :
Any problem with an answer, YES or NO.

\paragraph{P :} A decision problem that can be solved in polynomial time. That is, given an instance of the problem, the answer yes or no can be decided in polynomial time.

\subparagraph{\textit{Example : }} Given a graph connected G, can its vertices be colored using two colors so that no edge is monochromatic. Algorithm: start with an arbitrary vertex, color it red and all of its neighbors blue and continue. Stop when you run our of vertices or you are forced to make an edge have both of its endpoints be the same color.

\paragraph{NP :} A decision problem where instances of the problem for which the answer is yes have proofs that can be verified in polynomial time. This means that if someone gives us an instance of the problem and a certificate (sometimes called a witness) to the answer being yes, we can check that it is correct in polynomial time.

\subparagraph{\textit{Example:}} Integer factorization is NP. This is the problem that given integers n and m, is there an integer f with 1 < f < m such that f divides n (f is a small factor of n)? This is a decision problem because the answers are yes or no. If someone hands us an instance of the problem (so they hand us integers n and m) and an integer f with 1 < f < m and claim that f is a factor of n(the certificate) we can check the answer in polynomial time by performing the division n / f.

\paragraph{NP-complete :} An NP problem X for which it is possible to reduce any other NP problem Y to X in polynomial time. Intuitively this means that we can solve Y quickly if we know how to solve X quickly. Precisely, Y is reducible to X if there is a polynomial time algorithm f to transform instances x of X to instances y = f(x) of Y in polynomial time with the property that the answer to x is yes if and only if the answer to f(x) is yes.

\subparagraph{\textit{Example:}} 3-SAT. This is the problem wherein we are given a conjunction of 3-clause disjunctions (i.e., statements of the form

(x\_v11 or x\_v21 or x\_v31) and 
(x\_v12 or x\_v22 or x\_v32) and 
...                       and 
(x\_v1n or x\_v2n or x\_v3n)
where each x\_vij is a boolean variable or the negation of a variable from a finite predefined list (x\_1, x\_2, ... x\_n). It can be shown that every NP problem can be reduced to 3-SAT. The proof of this is technical and requires use of the technical definition of NP (based on non-deterministic Turing machines and the like). This is known as Cook's theorem.

What makes NP-complete problems important is that if a deterministic polynomial time algorithm can be found to solve one of them, every NP problem is solvable in polynomial time (one problem to rule them all).

\paragraph{NP-hard :} Intuitively these are the problems that are even harder than the NP-complete problems. Note that NP-hard problems do not have to be in NP (they do not have to be decision problems). The precise definition here is that a problem X is NP-hard if there is an NP-complete problem Y such that Y is reducible to X in polynomial time. But since any NP-complete problem can be reduced to any other NP-complete problem in polynomial time, all NP-complete problems can be reduced to any NP-hard problem in polynomial time. Then if there is a solution to one NP-hard problem in polynomial time, there is a solution to all NP problems in polynomial time.

The halting problem is the classic NP-hard problem. This is the problem that given a program P and input I, will it halt? This is a decision problem but it is not in NP. It is clear that any NP-complete problem can be reduced to this one.

\paragraph{P = NP :} This the most famous problem in computer science, and one of the most important outstanding questions in the mathematical sciences. In fact, the Clay Institute is offering one million dollars for a solution to the problem (Stephen Cook's writeup on the Clay website is quite good). It's clear that P is a subset of NP. The open question is whether or not NP problems have deterministic polynomial time solutions. It is largely believed that they do not. Here is an outstanding recent article on the latest (and the importance) of the P = NP problem: The Status of the P versus NP problem.

The best book on the subject is Computers and Intractability by Garey and Johnson. My favorite NP-complete problem is the Minesweeper problem.
\bibliographystyle{abbrv}
\bibliography{main}

\end{document}
